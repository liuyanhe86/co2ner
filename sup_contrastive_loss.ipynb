{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(profile='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.],\n",
       "        [ 7.,  8.,  9.],\n",
       "        [10., 11., 12.],\n",
       "        [13., 14., 15.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "b = torch.Tensor([[7,8,9], [10,11,12], [13,14,15]])\n",
    "torch.cat((a,b),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5405, -0.0218, -0.3455,  0.1786,  0.7457])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = torch.randn(5)\n",
    "F.normalize(embedding, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1202,  0.0534,  0.4551, -0.8527, -0.2203],\n",
       "        [-0.3674,  0.8867,  0.2422, -0.1004, -0.1002],\n",
       "        [-0.6232,  0.7248,  0.2256,  0.1132,  0.1500],\n",
       "        [ 0.4695,  0.0916, -0.2668, -0.4781, -0.6866],\n",
       "        [-0.4618,  0.0426,  0.6552, -0.5936,  0.0577],\n",
       "        [-0.5506,  0.2652,  0.3107, -0.2665,  0.6775],\n",
       "        [ 0.5242,  0.3289,  0.3215, -0.4149, -0.5844],\n",
       "        [-0.1140,  0.3257,  0.7817,  0.3853, -0.3486],\n",
       "        [ 0.6502, -0.3069, -0.0812,  0.0064, -0.6902],\n",
       "        [-0.2065, -0.6311,  0.5693,  0.0159,  0.4845]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = F.normalize(torch.randn(10,5), dim=1)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor([0,1,1,0,0,2,2,0,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.0000,  30.9469,   8.6748,  38.5924,  84.9417,  29.9760,  58.3367,\n",
       "          13.5135,   1.5001,  12.9935],\n",
       "        [ 30.9469, 100.0000,  89.9913,  -3.9088,  41.9938,  47.1563,  27.7121,\n",
       "          51.6273, -46.2144, -39.5910],\n",
       "        [  8.6748,  89.9913, 100.0000, -44.3535,  40.7908,  67.6953, -15.0436,\n",
       "          47.4779, -74.8818, -12.5751],\n",
       "        [ 38.5924,  -3.9088, -44.3535, 100.0000, -14.3502, -65.4863,  79.0061,\n",
       "         -17.7123,  76.9650, -64.6936],\n",
       "        [ 84.9417,  41.9938,  40.7908, -14.3502, 100.0000,  66.6372,  19.5193,\n",
       "          32.9882, -41.0162,  46.0017],\n",
       "        [ 29.9760,  47.1563,  67.6953, -65.4863,  66.6372, 100.0000, -38.6880,\n",
       "           5.3235, -93.3951,  44.7266],\n",
       "        [ 58.3367,  27.7121, -15.0436,  79.0061,  19.5193, -38.6880, 100.0000,\n",
       "          34.2547,  61.4509, -42.2503],\n",
       "        [ 13.5135,  51.6273,  47.4779, -17.7123,  32.9882,   5.3235,  34.2547,\n",
       "         100.0000,   0.5503,  10.0281],\n",
       "        [  1.5001, -46.2144, -74.8818,  76.9650, -41.0162, -93.3951,  61.4509,\n",
       "           0.5503, 100.0000, -32.1194],\n",
       "        [ 12.9935, -39.5910, -12.5751, -64.6936,  46.0017,  44.7266, -42.2503,\n",
       "          10.0281, -32.1194, 100.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_tempered = torch.mm(batch, batch.T) / temperature  # z_i \\dot z_j / \\tau\n",
    "dot_product_tempered.size()  # [dim, dim](10,10)\n",
    "dot_product_tempered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([[100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000]]),\n",
      "indices=tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]]))\n",
      "tensor([[   0.0000,  -69.0531,  -91.3252,  -61.4076,  -15.0583,  -70.0240,\n",
      "          -41.6633,  -86.4865,  -98.4999,  -87.0065],\n",
      "        [ -69.0531,    0.0000,  -10.0088, -103.9088,  -58.0062,  -52.8438,\n",
      "          -72.2879,  -48.3727, -146.2144, -139.5911],\n",
      "        [ -91.3252,  -10.0088,    0.0000, -144.3535,  -59.2092,  -32.3047,\n",
      "         -115.0436,  -52.5221, -174.8818, -112.5751],\n",
      "        [ -61.4076, -103.9088, -144.3535,    0.0000, -114.3502, -165.4863,\n",
      "          -20.9939, -117.7123,  -23.0350, -164.6936],\n",
      "        [ -15.0583,  -58.0062,  -59.2092, -114.3502,    0.0000,  -33.3628,\n",
      "          -80.4807,  -67.0118, -141.0162,  -53.9983],\n",
      "        [ -70.0240,  -52.8437,  -32.3047, -165.4863,  -33.3628,    0.0000,\n",
      "         -138.6880,  -94.6765, -193.3951,  -55.2734],\n",
      "        [ -41.6634,  -72.2879, -115.0436,  -20.9940,  -80.4807, -138.6881,\n",
      "            0.0000,  -65.7453,  -38.5491, -142.2504],\n",
      "        [ -86.4865,  -48.3727,  -52.5221, -117.7123,  -67.0119,  -94.6765,\n",
      "          -65.7453,    0.0000,  -99.4497,  -89.9719],\n",
      "        [ -98.4999, -146.2144, -174.8818,  -23.0350, -141.0162, -193.3951,\n",
      "          -38.5491,  -99.4497,    0.0000, -132.1194],\n",
      "        [ -87.0065, -139.5910, -112.5751, -164.6936,  -53.9983,  -55.2734,\n",
      "         -142.2503,  -89.9719, -132.1194,    0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0289e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e+00, 5.5004e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 5.5004e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05,\n",
       "         1.0001e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0289e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0001e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ele = torch.max(dot_product_tempered, dim=1, keepdim=True)\n",
    "print(max_ele)\n",
    "dot_product_tempered = dot_product_tempered - max_ele[0]\n",
    "print(dot_product_tempered)\n",
    "exp_dot_tempered = (\n",
    "    torch.exp(dot_product_tempered) \n",
    "    + 1e-5\n",
    ")  # exp(z_i \\dot z_j / \\tau)，每一行代表和每个其他嵌入的点积\n",
    "exp_dot_tempered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True]])\n",
      "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 分母是z_i与batch中其他嵌入的点积，因此要屏蔽掉exp_dot_tempered中自己与自己相乘的部分，即对角线上的取值\n",
    "unsqeezed_labels = labels.unsqueeze(1)  # [[0],[1],[1],[0],[0],[2],[2],[0],[3],[3]]\n",
    "repeated_labels = unsqeezed_labels.repeat(1, labels.shape[0])  # 每一行都是batch_size长的全为对应的样本的标签的向量\n",
    "mask_similar_class = (repeated_labels == labels)\n",
    "print(mask_similar_class)\n",
    "mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0]))  # 对角线为0其他全为1的batch_size * batch_size的张量\n",
    "print(mask_anchor_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_combined = mask_similar_class * mask_anchor_out\n",
    "mask_combined  # 每个样本在batch中相同样本的其他样本对应的位置为1，不同的为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 1., 1., 3., 3., 1., 1., 3., 1., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality_per_samples = torch.sum(mask_combined, dim=1)\n",
    "cardinality_per_samples  # batch中每个样本的与他标签相同的其他样本的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0289e-05],\n",
      "        [1.3500e-04],\n",
      "        [1.3500e-04],\n",
      "        [9.0001e-05],\n",
      "        [9.0289e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0001e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0000e-05]])\n",
      "tensor([[-9.3125,  2.2004,  2.2004,  2.2004,  2.1720,  2.2004,  2.2004,  2.2004,\n",
      "          2.2004,  2.2004],\n",
      "        [ 2.6027, -8.9102,  0.8979,  2.6027,  2.6027,  2.6027,  2.6027,  2.6027,\n",
      "          2.6027,  2.6027],\n",
      "        [ 2.6027,  0.8979, -8.9102,  2.6027,  2.6027,  2.6027,  2.6027,  2.6027,\n",
      "          2.6027,  2.6027],\n",
      "        [ 2.1972,  2.1972,  2.1972, -9.3157,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1720,  2.2004,  2.2004,  2.2004, -9.3125,  2.2004,  2.2004,  2.2004,\n",
      "          2.2004,  2.2004],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,  2.1972,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "         -9.3157,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "          2.1972, -9.3157]])\n"
     ]
    }
   ],
   "source": [
    "fenmu = torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)\n",
    "print(fenmu)\n",
    "log_prob = -torch.log(exp_dot_tempered / fenmu)\n",
    "print(log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, 0.0000, 0.0000, 2.2004, 2.1720, 0.0000, 0.0000, 2.2004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, -0.0000, 0.8979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.8979, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1972, 0.0000, 0.0000, -0.0000, 2.1972, 0.0000, 0.0000, 2.1972, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1720, 0.0000, 0.0000, 2.2004, -0.0000, 0.0000, 0.0000, 2.2004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, 2.1972, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1972, -0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1972, 0.0000, 0.0000, 2.1972, 2.1972, 0.0000, 0.0000, -0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
      "         2.1972],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1972,\n",
      "         -0.0000]])\n",
      "tensor([2.1909, 0.8979, 0.8979, 2.1972, 2.1909, 2.1972, 2.1972, 2.1972, 2.1972,\n",
      "        2.1972])\n",
      "tensor(19.3610)\n"
     ]
    }
   ],
   "source": [
    "log = log_prob * mask_combined\n",
    "print(log)\n",
    "supervised_contrastive_loss_per_sample = torch.sum(log, dim=1) / cardinality_per_samples\n",
    "print(supervised_contrastive_loss_per_sample)\n",
    "supervised_contrastive_loss = torch.sum(supervised_contrastive_loss_per_sample)\n",
    "print(supervised_contrastive_loss)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f8f18320cc0d9e782967693d965b6f1abb68e26a34d146b737af38164bc8375"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
