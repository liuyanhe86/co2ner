{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(profile='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.Tensor([[1,0,0]])\n",
    "print(zeros.any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3])\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.]])\n",
      "tensor([ 5.1962, 10.3923])\n",
      "tensor(7.7942)\n",
      "tensor(6.7500)\n",
      "tensor([0.1353, 0.0003])\n",
      "tensor(0.1357)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto = torch.Tensor([[1,2,3]])\n",
    "print(proto.size())\n",
    "print(proto.squeeze(0).shape)\n",
    "Z_p = torch.Tensor([[4,5,6], [7,8,9]])\n",
    "Z_c = torch.Tensor([[10,11,12], [13,14,15]])\n",
    "delta = Z_c - Z_p\n",
    "print(delta)\n",
    "dist = torch.sqrt(torch.sum(torch.pow(Z_p - proto, 2), dim=1))\n",
    "print(dist)\n",
    "dist_mean = torch.mean(dist)\n",
    "print(dist_mean)\n",
    "dist_variance = torch.mean(torch.pow(dist - dist_mean, 2))\n",
    "print(dist_variance)\n",
    "w = torch.exp(-torch.pow(dist, 2) / (2 * dist_variance))\n",
    "print(w)\n",
    "W = torch.sum(w)\n",
    "print(W)\n",
    "torch.sum(torch.unsqueeze(w, 1) * delta, dim=0) / W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1222, -0.7646,  0.0968, -0.6236, -0.0476])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = torch.randn(5)\n",
    "F.normalize(embedding, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4342,  0.1807,  0.7055, -0.2508,  0.4671],\n",
       "        [ 0.0895,  0.2692,  0.6800,  0.0687, -0.6727],\n",
       "        [ 0.3958,  0.6374,  0.3359,  0.5280,  0.2135],\n",
       "        [ 0.0264,  0.5472, -0.1960,  0.5855,  0.5645],\n",
       "        [-0.2456, -0.0579,  0.2585,  0.9231,  0.1318],\n",
       "        [ 0.2307, -0.3902,  0.5729,  0.6746,  0.1057],\n",
       "        [-0.2358,  0.8479,  0.4216, -0.2022, -0.0823],\n",
       "        [-0.3012, -0.5614,  0.5359,  0.5525, -0.0403],\n",
       "        [-0.1251,  0.4225,  0.1585, -0.4812, -0.7410],\n",
       "        [-0.4173, -0.0202, -0.2262,  0.8197,  0.3199]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = F.normalize(torch.randn(10,5), dim=1)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor([0,1,1,0,0,2,2,0,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.0000,  23.5807,  49.1227,   8.8848, -10.4697,  31.3988,  36.0607,\n",
       "          -1.1511,  -9.1560, -40.0674],\n",
       "        [ 23.5807, 100.0000,  32.8078, -32.3088,  11.3072,  28.0451,  53.5296,\n",
       "          25.1394,  67.5686, -35.5444],\n",
       "        [ 49.1227,  32.8078, 100.0000,  72.3005,  46.8280,  41.3767,  46.4409,\n",
       "          -1.3873, -13.9244,  24.7064],\n",
       "        [  8.8848, -32.3088,  72.3005, 100.0000,  52.6008,  13.4899,  21.0263,\n",
       "         -11.9435, -50.3236,  68.2788],\n",
       "        [-10.4697,  11.3072,  46.8280,  52.6008, 100.0000,  75.0730,  -7.9680,\n",
       "          74.9753, -49.4615,  84.3981],\n",
       "        [ 31.3988,  28.0451,  41.3767,  13.4899,  75.0730, 100.0000, -28.8826,\n",
       "          82.5112, -50.5886,  36.8759],\n",
       "        [ 36.0607,  53.5296,  46.4409,  21.0263,  -7.9680, -28.8826, 100.0000,\n",
       "         -28.7466,  61.2868, -20.6173],\n",
       "        [ -1.1511,  25.1394,  -1.3873, -11.9435,  74.9753,  82.5112, -28.7466,\n",
       "         100.0000, -35.0636,  45.5790],\n",
       "        [ -9.1560,  67.5686, -13.9244, -50.3236, -49.4615, -50.5886,  61.2868,\n",
       "         -35.0636, 100.0000, -62.3674],\n",
       "        [-40.0674, -35.5444,  24.7064,  68.2788,  84.3981,  36.8759, -20.6173,\n",
       "          45.5790, -62.3674, 100.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_tempered = torch.mm(batch, batch.T) / temperature  # z_i \\dot z_j / \\tau\n",
    "dot_product_tempered.size()  # [dim, dim](10,10)\n",
    "dot_product_tempered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([[100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000]]),\n",
      "indices=tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]]))\n",
      "tensor([[   0.0000,  -76.4193,  -50.8773,  -91.1152, -110.4697,  -68.6012,\n",
      "          -63.9392, -101.1510, -109.1560, -140.0674],\n",
      "        [ -76.4194,    0.0000,  -67.1922, -132.3088,  -88.6928,  -71.9549,\n",
      "          -46.4704,  -74.8606,  -32.4314, -135.5444],\n",
      "        [ -50.8773,  -67.1922,    0.0000,  -27.6995,  -53.1720,  -58.6233,\n",
      "          -53.5591, -101.3873, -113.9244,  -75.2936],\n",
      "        [ -91.1152, -132.3087,  -27.6995,    0.0000,  -47.3992,  -86.5101,\n",
      "          -78.9737, -111.9435, -150.3236,  -31.7212],\n",
      "        [-110.4697,  -88.6928,  -53.1720,  -47.3992,    0.0000,  -24.9270,\n",
      "         -107.9680,  -25.0247, -149.4615,  -15.6019],\n",
      "        [ -68.6012,  -71.9549,  -58.6233,  -86.5101,  -24.9270,    0.0000,\n",
      "         -128.8826,  -17.4889, -150.5887,  -63.1241],\n",
      "        [ -63.9392,  -46.4704,  -53.5591,  -78.9737, -107.9680, -128.8826,\n",
      "            0.0000, -128.7466,  -38.7132, -120.6173],\n",
      "        [-101.1510,  -74.8606, -101.3873, -111.9435,  -25.0247,  -17.4888,\n",
      "         -128.7466,    0.0000, -135.0636,  -54.4209],\n",
      "        [-109.1560,  -32.4314, -113.9244, -150.3236, -149.4615, -150.5886,\n",
      "          -38.7132, -135.0636,    0.0000, -162.3674],\n",
      "        [-140.0674, -135.5444,  -75.2936,  -31.7212,  -15.6019,  -63.1241,\n",
      "         -120.6174,  -54.4210, -162.3674,    0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0168e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00,\n",
       "         1.0000e-05, 1.0025e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0025e-05,\n",
       "         1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0168e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ele = torch.max(dot_product_tempered, dim=1, keepdim=True)\n",
    "print(max_ele)\n",
    "dot_product_tempered = dot_product_tempered - max_ele[0]\n",
    "print(dot_product_tempered)\n",
    "exp_dot_tempered = (\n",
    "    torch.exp(dot_product_tempered) \n",
    "    + 1e-5\n",
    ")  # exp(z_i \\dot z_j / \\tau)，每一行代表和每个其他嵌入的点积\n",
    "exp_dot_tempered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True]])\n",
      "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 分母是z_i与batch中其他嵌入的点积，因此要屏蔽掉exp_dot_tempered中自己与自己相乘的部分，即对角线上的取值\n",
    "unsqeezed_labels = labels.unsqueeze(1)  # [[0],[1],[1],[0],[0],[2],[2],[0],[3],[3]]\n",
    "repeated_labels = unsqeezed_labels.repeat(1, labels.shape[0])  # 每一行都是batch_size长的全为对应的样本的标签的向量\n",
    "mask_similar_class = (repeated_labels == labels)\n",
    "print(mask_similar_class)\n",
    "mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0]))  # 对角线为0其他全为1的batch_size * batch_size的张量\n",
    "print(mask_anchor_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_combined = mask_similar_class * mask_anchor_out\n",
    "mask_combined  # 每个样本在batch中相同样本的其他样本对应的位置为1，不同的为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 1., 1., 3., 3., 1., 1., 3., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality_per_samples = torch.sum(mask_combined, dim=1)\n",
    "cardinality_per_samples  # batch中每个样本的与他标签相同的其他样本的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0289e-05],\n",
      "        [1.3500e-04],\n",
      "        [1.3500e-04],\n",
      "        [9.0001e-05],\n",
      "        [9.0289e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0001e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0000e-05]])\n",
      "tensor([[-9.3125,  2.2004,  2.2004,  2.2004,  2.1720,  2.2004,  2.2004,  2.2004,\n",
      "          2.2004,  2.2004],\n",
      "        [ 2.6027, -8.9102,  0.8979,  2.6027,  2.6027,  2.6027,  2.6027,  2.6027,\n",
      "          2.6027,  2.6027],\n",
      "        [ 2.6027,  0.8979, -8.9102,  2.6027,  2.6027,  2.6027,  2.6027,  2.6027,\n",
      "          2.6027,  2.6027],\n",
      "        [ 2.1972,  2.1972,  2.1972, -9.3157,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1720,  2.2004,  2.2004,  2.2004, -9.3125,  2.2004,  2.2004,  2.2004,\n",
      "          2.2004,  2.2004],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,  2.1972,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "         -9.3157,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "          2.1972, -9.3157]])\n"
     ]
    }
   ],
   "source": [
    "fenmu = torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)\n",
    "print(fenmu)\n",
    "log_prob = -torch.log(exp_dot_tempered / fenmu)\n",
    "print(log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, 0.0000, 0.0000, 2.2004, 2.1720, 0.0000, 0.0000, 2.2004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, -0.0000, 0.8979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.8979, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1972, 0.0000, 0.0000, -0.0000, 2.1972, 0.0000, 0.0000, 2.1972, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1720, 0.0000, 0.0000, 2.2004, -0.0000, 0.0000, 0.0000, 2.2004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, 2.1972, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1972, -0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1972, 0.0000, 0.0000, 2.1972, 2.1972, 0.0000, 0.0000, -0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
      "         2.1972],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1972,\n",
      "         -0.0000]])\n",
      "tensor([2.1909, 0.8979, 0.8979, 2.1972, 2.1909, 2.1972, 2.1972, 2.1972, 2.1972,\n",
      "        2.1972])\n",
      "tensor(19.3610)\n"
     ]
    }
   ],
   "source": [
    "log = log_prob * mask_combined\n",
    "print(log)\n",
    "supervised_contrastive_loss_per_sample = torch.sum(log, dim=1) / cardinality_per_samples\n",
    "print(supervised_contrastive_loss_per_sample)\n",
    "supervised_contrastive_loss = torch.sum(supervised_contrastive_loss_per_sample)\n",
    "print(supervised_contrastive_loss)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f8f18320cc0d9e782967693d965b6f1abb68e26a34d146b737af38164bc8375"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
